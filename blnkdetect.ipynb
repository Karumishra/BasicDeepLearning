{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# detect the face rectangle \n",
    "def detect(img, cascade = face_cascade , minimumFeatureSize=(20, 20)):\n",
    "    if cascade.empty():\n",
    "        raise (Exception(\"There was a problem loading your Haar Cascade xml file.\"))\n",
    "    rects = cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=1, minSize=minimumFeatureSize)\n",
    "    \n",
    "    # if it doesn't return rectangle return array\n",
    "    # with zero lenght\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "\n",
    "    #  convert last coord from (width,height) to (maxX, maxY)\n",
    "    rects[:, 2:] += rects[:, :2]\n",
    "\n",
    "    return rects\n",
    "\n",
    "def cropEyes(frame):\n",
    "\t \n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t\n",
    "\t# detect the face at grayscale image\n",
    "\tte = detect(gray, minimumFeatureSize=(80, 80))\n",
    "\n",
    "\t# if the face detector doesn't detect face\n",
    "\t# return None, else if detects more than one faces\n",
    "\t# keep the bigger and if it is only one keep one dim\n",
    "\tif len(te) == 0:\n",
    "\t\treturn None\n",
    "\telif len(te) > 1:\n",
    "\t\tface = te[0]\n",
    "\telif len(te) == 1:\n",
    "\t\t[face] = te\n",
    "\n",
    "\t# keep the face region from the whole frame\n",
    "\tface_rect = dlib.rectangle(left = int(face[0]), top = int(face[1]),\n",
    "\t\t\t\t\t\t\t\tright = int(face[2]), bottom = int(face[3]))\n",
    "\t\n",
    "\t# determine the facial landmarks for the face region\n",
    "\tshape = predictor(gray, face_rect)\n",
    "\tshape = face_utils.shape_to_np(shape)\n",
    "\n",
    "\t#  grab the indexes of the facial landmarks for the left and\n",
    "\t#  right eye, respectively\n",
    "\t(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "\t(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "\t# extract the left and right eye coordinates\n",
    "\tleftEye = shape[lStart:lEnd]\n",
    "\trightEye = shape[rStart:rEnd]\n",
    "\n",
    "\t# keep the upper and the lower limit of the eye \n",
    "\t# and compute the height \n",
    "\tl_uppery = min(leftEye[1:3,1])\n",
    "\tl_lowy = max(leftEye[4:,1])\n",
    "\tl_dify = abs(l_uppery - l_lowy)\n",
    "\n",
    "\t# compute the width of the eye\n",
    "\tlw = (leftEye[3][0] - leftEye[0][0])\n",
    "\n",
    "\t# we want the image for the cnn to be (26,34)\n",
    "\t# so we add the half of the difference at x and y\n",
    "\t# axis from the width at height respectively left-right\n",
    "\t# and up-down \n",
    "\tminxl = (leftEye[0][0] - ((34-lw)/2))\n",
    "\tmaxxl = (leftEye[3][0] + ((34-lw)/2)) \n",
    "\tminyl = (l_uppery - ((26-l_dify)/2))\n",
    "\tmaxyl = (l_lowy + ((26-l_dify)/2))\n",
    "\t\n",
    "\t# crop the eye rectangle from the frame\n",
    "\tleft_eye_rect = np.rint([minxl, minyl, maxxl, maxyl])\n",
    "\tleft_eye_rect = left_eye_rect.astype(int)\n",
    "\tleft_eye_image = gray[(left_eye_rect[1]):left_eye_rect[3], (left_eye_rect[0]):left_eye_rect[2]]\n",
    "\t\n",
    "\t# same as left eye at right eye\n",
    "\tr_uppery = min(rightEye[1:3,1])\n",
    "\tr_lowy = max(rightEye[4:,1])\n",
    "\tr_dify = abs(r_uppery - r_lowy)\n",
    "\trw = (rightEye[3][0] - rightEye[0][0])\n",
    "\tminxr = (rightEye[0][0]-((34-rw)/2))\n",
    "\tmaxxr = (rightEye[3][0] + ((34-rw)/2))\n",
    "\tminyr = (r_uppery - ((26-r_dify)/2))\n",
    "\tmaxyr = (r_lowy + ((26-r_dify)/2))\n",
    "\tright_eye_rect = np.rint([minxr, minyr, maxxr, maxyr])\n",
    "\tright_eye_rect = right_eye_rect.astype(int)\n",
    "\tright_eye_image = gray[right_eye_rect[1]:right_eye_rect[3], right_eye_rect[0]:right_eye_rect[2]]\n",
    "\n",
    "\t# if it doesn't detect left or right eye return None\n",
    "\tif 0 in left_eye_image.shape or 0 in right_eye_image.shape:\n",
    "\t\treturn None\n",
    "\t# resize for the conv net\n",
    "\tleft_eye_image = cv2.resize(left_eye_image, (34, 26))\n",
    "\tright_eye_image = cv2.resize(right_eye_image, (34, 26))\n",
    "\tright_eye_image = cv2.flip(right_eye_image, 1)\n",
    "\t# return left and right eye\n",
    "\treturn left_eye_image, right_eye_image \n",
    "\n",
    "# make the image to have the same format as at training \n",
    "def cnnPreprocess(img):\n",
    "\timg = img.astype('float32')\n",
    "\timg /= 255\n",
    "\timg = np.expand_dims(img, axis=2)\n",
    "\timg = np.expand_dims(img, axis=0)\n",
    "\treturn img\n",
    "\n",
    "def main():\n",
    "\t# open the camera,load the cnn model \n",
    "\tcamera = cv2.VideoCapture(0)\n",
    "\tmodel = load_model('blinkModel.hdf5')\n",
    "\t\n",
    "\t# blinks is the number of total blinks ,close_counter\n",
    "\t# the counter for consecutive close predictions\n",
    "\t# and mem_counter the counter of the previous loop \n",
    "\tclose_counter = blinks = mem_counter= 0\n",
    "\tstate = ''\n",
    "\twhile True:\n",
    "\t\t\n",
    "\t\tret, frame = camera.read()\n",
    "\t\t\n",
    "\t\t# detect eyes\n",
    "\t\teyes = cropEyes(frame)\n",
    "\t\tif eyes is None:\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\t\t\tleft_eye,right_eye = eyes\n",
    "\t\t\n",
    "\t\t# average the predictions of the two eyes \n",
    "\t\tprediction = (model.predict(cnnPreprocess(left_eye)) + model.predict(cnnPreprocess(right_eye)))/2.0\n",
    "\t\t\t\n",
    "\t\t# blinks\n",
    "\t\t# if the eyes are open reset the counter for close eyes\n",
    "\t\tif prediction > 0.5 :\n",
    "\t\t\tstate = 'open'\n",
    "\t\t\tclose_counter = 0\n",
    "\t\telse:\n",
    "\t\t\tstate = 'close'\n",
    "\t\t\tclose_counter += 1\n",
    "\t\t\n",
    "\t\t# if the eyes are open and previousle were closed\n",
    "\t\t# for sufficient number of frames then increcement \n",
    "\t\t# the total blinks\n",
    "\t\tif state == 'open' and mem_counter > 1:\n",
    "\t\t\tblinks += 1\n",
    "\t\t# keep the counter for the next loop \n",
    "\t\tmem_counter = close_counter \n",
    "\n",
    "\t\t# draw the total number of blinks on the frame along with\n",
    "\t\t# the state for the frame\n",
    "\t\tcv2.putText(frame, \"Blinks: {}\".format(blinks), (10, 30),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\tcv2.putText(frame, \"State: {}\".format(state), (300, 30),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\t\t\n",
    "\t\t# show the frame\n",
    "\t\tcv2.imshow('blinks counter', frame)\n",
    "\t\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t\t# if the `q` key was pressed, break from the loop\n",
    "\t\tif key == ord('q'):\n",
    "\t\t\tbreak\n",
    "\t# do a little clean up\n",
    "\tcv2.destroyAllWindows()\n",
    "\tdel(camera)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "campenv",
   "language": "python",
   "name": "campenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
